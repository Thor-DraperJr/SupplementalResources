# AZ-500 Study Sessions

## Manage identity and access (30-35%)
### Manage Azure Active Directory identities
#### configure security for service principles
#### manage Azure AD directory groups
#### manage Azure AD users
#### manage administrative units
#### configure password writeback
#### configure authentication methods including password hash and Pass Through Authentication(PTA), OAuth, and passwordless
#### transfer Azure subscriptions between Azure AD tenants
### Configure secure access by using Azure AD
#### monitor privileged access for Azure AD Privleged Identity Management (PIM)
#### configure Access Reviews
#### activate and configure PIN
#### implement Conditional Access policies including Multi-Factor Authentication
#### configure Azure AD identity protection
### Manage application access
#### create App Registration
#### configure App Registration permission scopes
#### manage App Registration permission consent
#### manage API access to Azure subscriptions and resources
### Manage access control
#### configure subscription and resource permissions
#### configure resource group permissions
#### configure custom RBAC roles
#### identify the appropriate role
##### apply principle of least privilege
#### interpret permissions
##### check access
## Implement platformprotection (15-20%)
### Implement advanced network security
#### secure the connectivity of virtual networks (VPN authentication, Express Route encryption)
#### configure Network Security Groups (NSGs) and Application Security Groups (ASGs)
#### create and configure Azure Firewall
#### implement Azure Firewall Manager
#### configure Azure Front Door service as an Application Gateway
#### configure a Web Application Firewall (WAF) on Azure Application Gateway
#### configure Azure Bastion
#### configure a firewall on a storage account, Azure SQL, KeyVault, or App Service
#### implement Service Endpoints
#### implement DDoS protection
### Configure advanced Security for compute
#### configure endpoint protection
#### configure and monitor system updates for VMs
#### configure authentication for Azure Container Registry
#### configure security for different types of containers
##### implement vulnerability management
##### configure isolation for AKS
##### configure security for container registry
#### implement Azure Disk Encryption
#### configure authentication and security for Azure App Service
##### configure SSL/TLS certs
##### configure authentication for Azure Kubernetes Service
##### configure automatic updates
## Manage security operations (25-30%)
### Monitor security by using Azure Monitor
#### create and customize alerts
#### monitor security logs by using Azure Monitor
#### configure diagnostic logging and log retention
### Monitor security by using Azure Security Center
#### evaluate vulnerability scans from Azure Security Center
#### configure Just in Time VM access by using Azure Security Center
#### configure compliance policies and evaluate for compliance by using Azure Security Center
#### configure workflow automation by using Azure Security Center
### Monitor security by using Azure Sentinel
#### create and customize alerts
#### configure data sources to Azure Sentinel
#### evaluate results from Azure Sentinel
#### configure a playbook by using Azure Sentinel
### Configure security policies
#### configure security settings by using Azure Policy
#### configure security settings by using Azure Blueprint
## Secure data and applications (20-25%)
### Configure security for storage
#### configure access control for storage accounts
- https://docs.microsoft.com/en-us/rest/api/storageservices/define-stored-access-policy
    - Create a stored access policy
    - Modify a stored access policy
        - To modify the parameters of the stored access policy, you can call the access control list operation for the resource type to replace the existing policy, specifying a new start time, expiry time, or set of permissions. For example, if your existing policy grants read and write permissions to a resource, you can modify it to grant only read permissions for all future requests. In this case, the signed identifier of the new policy, as specified by the `ID` field, would be identical to the signed identifier of the policy you are replacing.
    - Revoke a stored access policy
        - To revoke a stored access policy, you can delete it, rename it by changing the signed identifier, or change the expiry time to a value in the past. Changing the signed identifier breaks the associations between any existing signatures and the stored access policy. Changing the expiry time to a value in the past causes any associated signatures to expire. Deleting or modifying the stored access policy immediately affects all of the shared access signatures associated with it. To remove a single access policy, call the resource's `Set ACL` operation, passing in the set of signed identifiers that you wish to maintain on the container. To remove all access policies from the resource, call the Set ACL operation with an empty request body.
#### configure key management for storage accounts
#### configure Azure AD authentication for Azure Storage
#### configure Azure AD Domain Services authentication for Azure Files
#### create and manage Shared Access Signatures (SAS)
##### create a shared access policy for a blob or blob container
#### configure Storage Service Encryption
#### configure Azure Defender for Storage
### Configure security for databases
#### enable database authentication
#### enable database auditing
#### configure Azure Defender for SQL
##### configure Azure SQL Database Advanced Threat Protection
#### implement database encryption
##### implement Azure SQL Database Always Encrypted
### Configure and manage Key Vault
#### manage access to Key Vault
#### manage permissions to secrets, certificates, and keys
##### configure RBAC usage in Azure Key Vault
#### manage certificates
#### manage secrets
#### configure key rotation
#### backup and restore of Key Vault items
#### configure Azure Defender for Key Vault




## Configure AAD for work
### Create App Registration
App registration (AAD Premium P2, Global Admin):
- this application can bu authorized an used by users
- any user who is a member of the AD can register an app(not a guest user)
 - an equivalent of adding a workstation to a domain

* AAD - contains a unique tenant ID
1. Navigate the left pane to App registration
2. New Registration
    * Name
    * Single tenant = default [Any Azure AD - Multitenant/ + personal Microsoft]
    * Redirect URI (optional)
        * Web = default (used for most authentication scenarios. mandates https)
3. Register

* ISV: independent software vendor

### Configure App Registration permission scopes
#### Terms
* scoping
* delegated permisstions = app interacts with a signed in user and binds proper constraints
* OAuth 2.0 = permissions are called scope

- In the left pane for Authentication it allows you to manage URI's for redirects

API permissions = Configured permissions

Microsoft Graph is the default microsoft provided permission to 'Sign in and read user profile', can be removed but shouldn't.

Adding an API permission
Options: Microsoft APIs, 
Supported legacy apps are on the bottom

Types of permissions: Delegated permissions (The application assumes the persona of the user to behave on behalf of the user) / Application permissions (no signed in users needed)

### Manage App Resgistration permission consent
proves right person to right level of access. 

Grants consent on behalf of the users in the AADD

**Tip:** https://myapps.microsoft.com

### Configure Multi-Factor Authentication security
* Security > Left pane, under the Manage subsection
* Click MFA
    * Account Lockout - specify locoucks for too man denials in a row that only applies to users who enter a PIN to authenticate
        * number of denials to trigger, minute s until rest, minutes until account is unblocked
    * Block/unblock users
        * Adding a user - prevents them from receiving the MFA prompt (auto blocked for 90 days)
    * Fraud Alert - allows user to report fraud if they receive a two-step verification request
        * Default is off
    * Notifications - the global admin is automatically listed
        * One-time bypass = a temporary allow for a user to authenticate for a default time period [default is 300 seconds - 5 min.]
        * Activity report = can see who has activated and usage logs
    * in the security section > Named locations > Configure MFA IPs
        * allows for whitelisting internal IPs
        * allows for remembering MFA for a set amount of days for trusted devices

### Manage Azure AD directory groups
* two-stage deletion process
* export capability
* naming convention controls

* types of groups: security, distribution, Office365, on-prem

**can only manage on-prem ON-PREM**

Navigate to AAD > Manage > Groups
* In groups
    * Settings
        * General
            * Self Service Group Management - owners can manage membership request in the access panel
            * Security Groups
            * Office 365 Groups
            * Directory-wide Groups
        * Expiration
            * useful for business cycles or project driven needs to timebound a group
            * Group lifetime (in days)
            * Notification for expiration reminders hapen 30, 15, 1 day (email only)
            * if not renewed the group is deleted
        * Naming policy
            * Blocked words - .csv of banned words (profanity, internal anames) and upload the csv
            * Group naming policy - unique only to Office 365 groups
                * add prefix / add suffix
    * Bulk operation results
        * you can export all groups from the main group page
        * hosts the results where you can download in a csv
        * does not contain memberships
        * useful for auditing what groups exists / automation

#### Deleting groups
- You can initially delete from the group list
- Navigate to Deleted groups 
    - You can Delete permanently or restore
    - Groups are held in delete for 30 days

#### Managing Licenses
- Choose a Security Group
    - Licenses
        - You can select licenses and services you want to enable or disable

### Manage Azure AD Users
- Roles and administrators
    - how you give and assign users roles and delegated rights

#### User v Guest User
- User = Known as members [Internal accounts]
    - Either AAD or Windows Server AD
- Guest Users = outside of the organization (contractors, end-users)
    - Invited User
    - Can be created or invited
        - creating a new user in the org will allow you to create and apply a domain (say you need it for multiple business units to give access to named directories). you can reset passwords
        - inviting a user creates the account as the invite is sent

#### Deleting a User
- You need to go into the username from the menu
- Deleted users go into the 'Deleted users' option
    - can be permanently delted or restored (30 day)

#### Password Reset
- You can enable 'Self service passwords'
    - Apply to end users in your oganization
    - Admins auto-enrolled
    - require two methods of verification

#### User Settings
- Admin portal
- LinkedIn Account SSO

#### Roles and Administators
- Assignments : allow you to choose users (like application admin or application developer)

*you can manage licenses to users the same way*

### Install and Configure Azure AD Connect
* AD Connect tool
    * Express Install - requires a routable (.com) domain
        * Customize Install
            * Specify a custom installation location = Default is C:\Program Files\Microsoft
        * User sign-in
        * Connecting to Azure AD = Requires Global admin credentials
* For SSO Create a GPO
    * Site to Zone Assignment List > Edit to enable
        * https://autologon.microsoftazuread-sso.com | Data: 1

    * **Tip** Must be 2012 or newer
    * Ideally domain joined not the DC

### Configure Authentication Methods
* Do you want Azure AD to handle Sign-in COMPLETELY in the cloud?

* Hash sychronize is a big factor in between on-prem / cloud envirnements because both environments need to sychronize for changes

* You can add multiple authentication methods

* Seamless SSO = allows users to us the same credentials to access other Azure resources

* Pass-through = No integrated federation, no 

##### Define the options after looking into the portal****

### Implement Conditional Access policies
* Conditional access
    * signals - users, endpoint type OS 
    * decisions - what you grant to the user

* AAD
    * Security > Conditional Access | Policies
        * Policy types: 
            * Baseline - msft defaults
            * Standard - admin created and modified
            * Classic - legacy policies

While creating policies the default is to Report-only to see how policies would be applied.

### Configure Azure AD Identity protection
In Azure AD - Premium P2 > Security > Identity Protection

* Overview
    * Scorecard data
        * Contains 90 days of historical data
    * New Risky sign-ins
        * Relation to baseline/standard policies

* Protect | Sign-in risk policy
    * Assign Users
    * Conditions
        * risk level
    * Controls
        * Block, allow
        * Require MFA
    * Enforce the Policy or not for users

* Leaked credentials - if your credentials show up on an online db [dark web id?]

* Notify | 
    * add additional users

*Global Admin isn't the only account that has access to this tab. Global reader, security reader and others are able to view Identity Protection(good fit for cso)*

## Configure Azure AD Priveleged Identity Management

### Activate Privileged Identity Management

Search Azure AD Priveleged Identity Managment (launches the blade)

PIM allos JIT (just in time) management. To give a fixed amount of time (ex. a business day) Time bounding use of time

RBAC

security admin
priveleged administrator role


* Tasks
    * My roles
    * My requests
    * Approve Requests
    * Review access
* Manage 
    * Azure AD roles
        * *Sign up = create/assins necessary roles and signs them up to the user initializing*
        *
    * Azure resources
        * where you can manage resouces outside of AD
* Activity
    * My audit history-

### Monitor Privieleged Access
- Licensing
    - Premium P2, E5 (ERM brings P2)
    - roles every administrator other than global admins needs a license for PIM
    - users managed by PIM need it, approvers need it, and reviewers need it
    - Users assigned as eligible to Azure AD roles managed using PIM
    - Users able to approve or reject activation requests in PIM
    - Users assigned to an Azure resource role with just-in-time or direct

The top 10 Azure AD roles managed by Privileged Identity Management are:

1. Global administrator
2. Security administrator
3. User administrator
4. Exchange administrator
5. SharePoint administrator
6. Intune administrator
7. Security reader
8. Service administrator
9. Billing administrator
10. Skype for Business administrator


PIM emails for Azure resource roles - Privileged Identity Management sends emails to Owners and User Access Administrators when the following events occur for Azure resource roles:

* When a role assignment is pending approval
* When a role is assigned
* When a role is soon to expire
* When a role is eligible to extend
* When a role is being renewed by an end user
* When a role activation request is completed

Privileged Identity Management sends emails to end users when the following events occur for Azure resource roles:

* When a role is assigned to the user
* When a user's role is expired
* When a user's role is extended
* When a user's role activation request is completed

### Configure Access Reviews

* Prerequistes
    * Azure AD Premium P2
    * Global admin or User admin

Navigate to Azure AD > Identity Governance
* Access reviews
    * Access reviews
        * Create an access review
            * Review name*
            * Description
            * Start date*
            * Frequency
            * End [Never, End by, Occurances]
            * Users
            * Scope - *You would need to create two if you wanted to audit both groups*
                * Guests
                * Everyone (does not include Guests)

Reviews are hosted at myaccess.microsoft.com

## Configure Azure tenant security

### Transfer Azure subs between Azure AD tenants
Navigate to 'Cost Management + Billing' 

* Billing
    * Subscriptions - In the options you can hit the elipses

You do this by emailing the subscription. You can change billing admins not necessarirly the entire tenant.

This removes RBAC permissions to manage Azure resources in the subscription

### Manage API access Azure subscriptions and resources

Authentication and Authorization steps

#### OAuth 2.0
The basic steps required to use the OAuth 2.0 authorization code grant flow to get an access token from the Microsoft identity platform endpoint are:

1. Register your app with Azure AD
2. Get authorization (/authorize endpoint) & Consent Experience
3. Get an access token (/token endpoint)
4. Call Microsoft Graph with the access token
5. Use a refresh token to get a new access token

## Implement network security

### Configure virtual netowrk connectivity
* Virtual network access settings are enabled by default and traffic forwarding is disabled
* Have to add IPv6 if you want that address space

Access to cloud shell
* shell.azure.com
    * editor is similar to ISE

### Create & Configure Network & Application Security Groups
* Network Security Groups (NSG) - uses security rules [similar to access control lists], manages stateful traffic/stateful filtering
    * managed rules for connections to the vnet
    * NSGs manage:
        * protocol - tcp, udp, icmp or any
        * direction - inbound or outbound
        * port range
        * action - allow or deny

* 5-tuple information (source, source port, destination, destination port, and protocol) to allow or deny the traffic.

### Create NSGs and ASGs
1. create a vnet
2. create ASG
3. create NSG
4. associate network sec group to subnet
5. create sec rule
6. create vms
7. associate network interfaces to asg

* Defualts
    * AllowVnetInBound
    * AllowAllowLoadBalancer
    * DenyAllInBound

### Create and configure Azure Firewall
* Firewall solution (Firewall as a Service)
* Scalable solution

* tied into log analytics, has it's own public IP, integrate with SEIM (sec incident and management)

Azure Firewall is a managed, cloud-based network security service that protects your Azure Virtual Network resources. It is a fully stateful firewall as a service with built-in high availability and unrestricted cloud scalability.

You can centrally create, enforce, and log application and network connectivity policies across subscriptions and virtual networks. Azure Firewall uses a static public IP address for your virtual network resources allowing outside firewalls to identify traffic originating from your virtual network. The service is fully integrated with Azure Monitor for logging and analytics.

* Stadard SKU Public IP and Static only

* Forced Tunneling : 

* Threat intelligence - off, alert only, alert and deny

* Rules - NAT Rule collection | Network rule collection | Application rule collection

### Configure resource Firewall
The *resource firewall* allows us to restrict access to an Azure service that supports the resource firewall feature. Azure storage accounts are one area where that is supported, as are Azure SQL Server and databases as well as Azure SQL Data Warehouse. In fact for Azure SQL, you can actually configure firewall rules at both the server level and the database level. You can use PowerShell, Azure CLI and the Azure Portal.

The *Azure storage firewall* provides access control for the public endpoint of your storage account. You can also use the firewall to block all access through the public endpoint when using private endpoints. Your storage firewall configuration also enables select trusted Azure platform services to access the storage account securely.

An application that accesses a storage account when network rules are in effect still requires proper authorization for the request. Authorization is supported with Azure Active Directory (Azure AD) credentials for blobs and queues, with a valid account access key, or with a SAS token.

* Object bound instances - specify vnet, subnet, address range, endpoint status, rg. You specify stateful connections in and out.

### Create and Configure Azure Front Door service
Azure Front Door Service enables you to define, manage, and monitor the global routing for your web traffic by optimizing for best performance and instant global failover for high availability.

Front Door works at **Layer 7** or HTTP/HTTPS layer and uses anycast protocol with split TCP and Microsoft's global network for improving global connectivity. So, per your routing method selection in the configuration, you can ensure that Front Door is routing your client requests to the fastest and most available application backend.

An application backend is any Internet-facing service hosted inside or outside of Azure.

* HA for web apps

#### Features of Front Door
* accelerate application performance
* increase application availibility with smart health probes
* url-based routing
* multi-site hosting
* session affinity
* ssl termination
* custom domains and cert management
* application layer security
* url redirection
* url rewrite
* protocol support

#### Setting up front door
* <hostname>.azurefd.net

* Setting up a frontend
    * Session Affinity, Web Application Firewall - disabled by default
* Setting up the backend pools
    * backed unique web app names **azurewebsites.net**
* A routing rule maps your frontend host to the backend pool. The rule forwards a request for contoso-frontend.azurefd.net to myBackendPool.

### Configure remote access management
* A virtual network gateway is composed of two or more VMs that are deployed to a specific subnet you create called the gateway subnet. Virtual network gateway VMs contain routing tables and run specific gateway services.

* Gateway types - VPN, ExpressRoute
    * VPN - from on prem to azure (Site 2 Site)
        *  SKUs named and number (ex. VpnGw1 - VpnGw5), higher the more expensive. Basic is also a SKU but can only be a Generation1.

    * Express Route - dedicated connectivity through an ISP

* Adding a Connection
    * Connection Type
        * VNet-to-VNet
        * Site-to-site (IPsec)
        * Express Route
    * Shared key (PSK)*
    * First VNG
    * Second VNG

* Point-to-site
    * Address pool - must be unique
    * Tunnel type
    * Authentication type

// A drawing would be nice

### Configure baseline
What is Azure Policy? -

Azure Policy helps to enforce organizational standards and to assess compliance at-scale. Through its compliance dashboard, it provides an aggregated view to evaluate the overall state of the environment, with the ability to drill-down to the per-resource, per-policy granularity. It also helps to bring your resources to compliance through bulk remediation for existing resources and automatic remediation for new resources.

* Baselining isn't an option - it's a combination of following best practices. Leveraging azure policy to do so

* After creating a policy you can assign a policy

* Definitions : looking at existing elements or create new
    * location = subscription

## Implement host security

### Configure endpoint security within the VM
* Protect VMs by using authentication and access control
* use multiple vms for better availability
* protect agains malware
* manage your vm updates
* manage your vm security posture
* monitor vm performance
* encrypt your virtual hard disk files
* restrict direct internet connectivty

- Share responsibility to ASC

- Detail: Use a least privilege approach and built-in Azure roles to enable users to access and set up VMs:
    - Virtual Machine Contributor: Can manage VMs, but not the virtual network or storage account to which they are connected.

### Configure VM security & Configure baseline
Configuring the baseline is about going from the "as-is" to the "to be"

### Configure system updates for VMs in Azure

## Configure container security

### Configure networking
* choose the appropriate network model
    * kubenet vs. azure CNI networking
* Distribute ingress traffic
    * An ingress resource & an ingress controller
* Secure traffic with a web application firewlall (WAF)
* Control traffic flow with network policies
    * Azure vs. Calico
* Securely connect to nodes through a bastion host

### Configure authentication
Security best practices for AKS authentication
* use azure active directory
    * roles or clusterroles bound to users
* use role-based access controls (RBAC)
    * Permissions can be defined at the lcuster level, or to specific namespaces
* Use Pod Identities
    * the node magement identity (NMI) server : listens for pod requrest to Azure services
    * the managed identity controller (MIC) : checks for an azure identity mapping that corresponds to a pod

### Configure container isolation
As you manage clusters in Azure Kubernetes Service (AKS), you often need to isolate teams and workloads. The Kubernetes scheduler provides features that let you control the distribution of compute resources, or limit the impact of maintenance events.

Resource requests and limits are placed in the pod specification. These limits are used by the Kubernetes scheduler at deployment time to find an available node in the cluster. These limits and requests work at the individual pod level.

Best practice guidance - Plan and apply resource quotas at the namespace level. If pods do not define resource requests and limits, reject the deployment. Monitor resource usage and adjust quotas as needed.

Best practice guidance - To maintain the availability of applications, define Pod Disruption Budgets (PDBs) to make sure that a minimum number of pods are available in the cluster.
* Involuntary disruptions are events beyond the typical control of the cluster
* Voluntary disruptions are events requested by the cluster operator

Cluster networking
* public: URI = ".westus2.azurecontiner.io"
* private:
* none

### Configure AKS Security
Major areas to focus on for AKS security
- master components
- node security
    - node (doing the work for the payload in the backgroud)
    - keeping nodes up to date can be a challenge
- cluster upgrades
- network security
- kubernetes secrets
    - Azure Key Vault
    - Never hard code API Access Keys (the common mistake for companies)


Master security -

In AKS, the Kubernetes master components are part of the managed service provided by Microsoft. Each AKS cluster has its own single-tenanted, dedicated Kubernetes master to provide the API Server, Scheduler, etc. This master is managed and maintained by Microsoft.

By default, the Kubernetes API server uses a public IP address and a fully qualified domain name (FQDN). You can limit access to the API server endpoint using authorized IP ranges. You can also create a fully private cluster to limit API server access to your virtual network.

You can control access to the API server using Kubernetes role-based access controls and Azure Active Directory.

Node security -

AKS nodes are Azure virtual machines that you manage and maintain. Linux nodes run an optimized Ubuntu distribution using the Moby container runtime. Windows Server nodes run an optimized Windows Server 2019 release and also use the Moby container runtime.

When an AKS cluster is created or scaled up, the nodes are automatically deployed with the latest OS security updates and configurations.

The Azure platform automatically applies OS security patches to Linux nodes on a nightly basis. If a Linux OS security update requires a host reboot, that reboot is not automatically performed. You can manually reboot the Linux nodes, or a common approach is to use Kured, an open-source reboot daemon for Kubernetes.

Kured runs as a DaemonSet and monitors each node for the presence of a file indicating that a reboot is required. Reboots are managed across the cluster using the same cordon and drain process as a cluster upgrade.

For Windows Server nodes, Windows Update does not automatically run and apply the latest updates. On a regular schedule around the Windows Update release cycle and your own validation process, you should perform an upgrade on the Windows Server node pool(s) in your AKS cluster.

This upgrade process creates nodes that run the latest Windows Server image and patches, then removes the older nodes.

NOTE: Nodes are deployed into a private virtual network subnet, with no public IP addresses assigned. For troubleshooting and management purposes, SSH is enabled by default. This SSH access is only available using the internal IP address.

To provide storage, the nodes use Azure Managed Disks. For most VM node sizes, these are Premium disks backed by high-performance SSDs. The data stored on managed disks is automatically encrypted at rest within the Azure platform. To improve redundancy, these disks are also securely replicated within the Azure datacenter.

Kubernetes environments, in AKS or elsewhere, currently are not completely safe for hostile multi-tenant usage.

Additional security features such as Pod Security Policies or more fine-grained role-based access controls (RBAC) for nodes make exploits more difficult.

However, for true security when running hostile multi-tenant workloads, a hypervisor is the only level of security that you should trust. The security domain for Kubernetes becomes the entire cluster, not an individual node.

For these types of hostile multi-tenant workloads, you should use physically isolated clusters.

Cluster upgrades -

For security and compliance, or to use the latest features, Azure provides tools to orchestrate the upgrade of an AKS cluster and components. This upgrade orchestration includes both the Kubernetes master and agent components.

You can view a list of available Kubernetes versions for your AKS cluster. To start the upgrade process, you specify one of these available versions. Azure then safely cordons and drains each AKS node and performs the upgrade.

Cordon and drain -

During the upgrade process, AKS nodes are individually cordoned from the cluster so new pods are not scheduled on them. The nodes are then drained and upgraded as follows:

* A new node is deployed into the node pool. This node runs the latest OS image and patches.

* One of the existing nodes is identified for upgrade. Pods on this node are gracefully terminated and scheduled on the other nodes in the node pool.

* This existing node is deleted from the AKS cluster. 
* The next node in the cluster is cordoned and drained using the same process until all nodes are successfully replaced as part of the upgrade process.

Network security -

For connectivity and security with on-premises networks, you can deploy your AKS cluster into existing Azure virtual network subnets.

These virtual networks may have an Azure Site-to-Site VPN or Express Route connection back to your on-premises network.

Kubernetes ingress controllers can be defined with private, internal IP addresses so services are only accessible over this internal network connection.

Azure network security groups -

To filter the flow of traffic in virtual networks, Azure uses network security group rules. These rules define the source and destination IP ranges, ports, and protocols that are allowed or denied access to resources.

Default rules are created to allow TLS traffic to the Kubernetes API server. As you create services with load balancers, port mappings, or ingress routes, AKS automatically modifies the network security group for traffic to flow appropriately.

Kubernetes network policy -

To limit network traffic between pods in your cluster, AKS offers support for Kubernetes network policies. With network policies, you can choose to allow or deny specific network paths within the cluster based on namespaces and label selectors.

Kubernetes Secrets -

A Kubernetes Secret is used to inject sensitive data into pods, such as access credentials or keys. You first create a Secret using the Kubernetes API.

When you define your pod or deployment, a specific Secret can be requested. Secrets are only provided to nodes that have a scheduled pod that requires it, and the Secret is stored in tmpfs, not written to disk.

When the last pod on a node that requires a Secret is deleted, the Secret is deleted from the node's tmpfs. Secrets are stored within a given namespace and can only be accessed by pods within the same namespace.

The use of Secrets reduces the sensitive information that is defined in the pod or service YAML manifest. Instead, you request the Secret stored in Kubernetes API Server as part of your YAML manifest.

This approach only provides the specific pod access to the Secret.

NOTE: The raw secret manifest files contains the secret data in base64 format (see the official documentation for more details). Therefore, this file should be treated as sensitive information, and never committed to source control.

### Configure container registry
Where you put your images
- reproducing the docker-style registry

images are registered in a secure docker registry to manage the images/workloads

- url for azure container registry must be globally unizque in azure "azurecr.io"

- sku types
    - basic
    - standard
    - premium : AzFw and other security options, Private endpoint connections, Customer-Managed Key-ing

- in order to upload a image to the directory you need to use powershell (not cloud cli)
    - azure cli allows you to log in and authenticate, docker installed on your local machine allows you to use the docker commands

### Implement vulnerability management
CI/CD - DevOps lifecycle

- approved venders
    - aqua/twistlock - container security companies; they check the registry changes and the production cluster

## Implement Azure Resource Management

### Create Azure resource locks
- resource locks
    - APIs that bound objects as ReadOny or CanNotDelete (users can still modify)

- Who can create or delete locks? 
    - To create or delete management locks, you must have access to Microsoft.Authorization/* or Microsoft.Authorization/locks/* actions.

- Blueprints
    - definitions / assignments
    - build the logic in a workflow to create a template that can be assigned to users

### Managing security using policies, resource groups, roles and permissions
- Azure Policy
    - Azure Policy helps to enforce organizational standards and to assess compliance at-scale. Through its compliance dashboard, it provides an aggregated view to evaluate the overall state of the environment, with the ability to drill-down to the per-resource, per-policy granularity. It also helps to bring your resources to compliance through bulk remediation for existing resources and automatic remediation for new resources. Common use cases for Azure Policy include implementing governance for resource consistency, regulatory compliance, security, cost, and management. Policy definitions for these common use cases are already available in your Azure environment as built-ins to help you get started.
    - has the scorecard for compliance
    - has remediation steps
    - authored by assignments/definitions

- roles and permissions
    - set in azure AD

- How can I control the response to an evaluation?
    - Examples of how an organization wants the platform to respond to a non-complaint resource include:
        - Deny the resource change
        - Log the change to the resource
        - Alter the resource before the change
        - Alter the resource after the change
        - Deploy related compliant resources
    - The following are the times or events that cause a resource to be evaluated:
        - A resource is created, updated, or deleted in a scope with a policy assignment.
            - A policy or initiative is newly assigned to a scope.
            - A policy or initiative already assigned to a scope is updated
            - During the standard compliance evaluation cycle, which occurs once every 24 hours.


## Configure security services

### Configure Azure Monitor
- very similar to SCOM (system center operations manager); intune, log analytic capabilities, agent based monitoring

- Just a few examples of what you can do with Azure Monitor include:
    - Detect and diagnose issues across applications and dependencies with Application Insights
    - Correlate infrastructure issues with Azure Monitor for VMs and Azure Monitor for Containers
    - Drill into your monitoring data with Log Analytics for troubleshooting and deep diagnostics
    - Support operations at scale with smart alerts and automated actions 
    - Create visualizations with Azure dashboards and workbooks
        - NOTE: This service supports Azure delegated resource management, which lets service providers sign in to their own tenant to manage subscriptions and resource groups that customers have delegated.

    **Azure Monitor** *Charges by ingestion amounts and retention amounts*

- All data collected by Azure Monitor fits into one of two fundamental types, metrics and logs.
    - Metrics are numerical values that describe some aspect of a system at a particular point in time. They are lightweight and capable of supporting near real-time scenarios.
    - Logs contain different kinds of data organized into records with different sets of properties for each type. Telemetry such as events and traces are stored as logs in addition to performance data so that it can all be combined for analysis.

- What data does Azure Monitor collect?
    - Azure Monitor can collect data from a variety of sources. You can think of monitoring data for your applications in tiers ranging from your application, any operating system and services it relies on, down to the platform itself.
    - Azure Monitor collects data from each of the following tiers:
        - Application monitoring data - Data about the performance and functionality of the code you have written, regardless of its platform.
            - Guest OS monitoring data - Data about the operating system on which your application is running. This could be running in Azure, another cloud, or on-premises.
            - Azure resource monitoring data - Data about the operation of an Azure resource.
            - Azure subscription monitoring data - Data about the operation and management of an Azure subscription, as well as data about the health and operation of Azure itself.
            - Azure tenant monitoring data - Data about the operation of tenant-level Azure services, such as Azure Active Directory.
                - NOTE: Azure Monitor can collect log data from any REST client using the Data Collector API. This allows you to create custom monitoring scenarios and extend monitoring to resources that do not expose telemetry through other sources.

### Configure diagnostic logging and log retention
- Each Azure resource requires its own diagnostic setting, which defines the following criteria:
    - Categories of logs and metric data sent to the destinations defined in the setting. The available categories will vary for different resource types.
    - One or more destinations to send the logs. Current destinations include Log
    - A single diagnostic setting can define no more than one of each of the destinations. If you want to send data to more than one of a particular destination type (for example, two different Log Analytics workspaces), then create multiple settings. Each resource can have up to 5 diagnostic settings.

- Destinations
    - Platform logs and metrics can be sent to the destinations in the following list:
    - Log Analytics workspace	- Collecting logs and metrics into a Log Analytics workspace allows you to analyze them with other monitoring data collected by Azure Monitor using powerful log queries and also to leverage other Azure Monitor features such as alerts and visualizations.
    - Event hubs - Sending logs and metrics to Event Hubs allows you to stream data to external systems such as third-party SIEMs and other log analytics solutions.
    - Azure storage account - Archiving logs and metrics to an Azure storage account is useful for audit, static analysis, or backup. Compared to Azure Monitor Logs and a Log Analytics workspace, Azure storage is less expensive and logs can be kept there indefinitely.

- Data retention
    - 30 Days to 730 (2 years)

### Configure vulnerability scanning
The vulnerability scanner included with Azure Security Center is powered by Qualys. It is only available to users on the standard pricing tier. You do not need a Qualys license or even a Qualys account - everything's handled seamlessly inside Security Center.

Your VMs will appear in one or more of the following groups:
* Healthy resources – the vulnerability scanner extension has been deployed to these VMs.
* Unhealthy resources – the vulnerability scanner extension can be deployed to these VMs.
* Not applicable resources – these VMs cannot have the vulnerability scanner extension deployed.

- Click Remdiate to change the VM

Security Center > Resource Security Hygiene | Recommendations > This will bring broad remediation across the domain

* What is scanned by the built-in vulnerability scanner?

The scanner is running on your virtual machine and looking for vulnerabilities of the VM itself. From the virtual machine, it cannot scan your network.

* Does the scanner integrate with my existing Qualys console?

The Security Center extension is a separate tool from your existing Qualys scanner. Licensing restrictions mean that it can only be used within Azure Security Center.

* How do I View and remediate discovered vulnerabilities? -

When Security Center identifies vulnerabilities, it presents findings and related information as recommendations. The related information includes remediation steps, related CVEs, CVSS scores, and more. You can view the identified vulnerabilities for one or more subscriptions, or for a specific VM.

## Manage security alerts
### Alerts- create, customize, review and respond
Monitor > Monitor | Alerts

Create alert rule > Scope (Select a resource, and the hierarchy is applied) > Condition > Add action group (select security group and determine an action) > Alert rule details (name, description)

**You can only define one Activity Log signal per alert rule. To alert on more signals, create additional rules**

* Log Alerts: With the visualization in place, Alert Logic can be selected from shown options of Condition, Aggregation and finally Threshold. Finally specify in the logic, the time to assess for the specified condition, using Period option. Along with how often Alert should run by selecting Frequency. Log Alerts can be based on:
 * Number of Records: An alert is created if the count of records returned by the query is either greater than or less than the value provided.
 * Metric Measurement: An alert is created if each aggregate value in the results exceeds the threshold value provided and it is grouped by chosen value. The number of breaches for an alert is the number of times the threshold is exceeded in the chosen time period. You can specify Total breaches for any combination of breaches across the results set or Consecutive breaches to require that the breaches must occur in consecutive samples.
 * *For Log Alerts only, some additional functionality is available in Alert details:*
  * Suppress Alerts: When you turn on suppression for the alert rule, actions
for the rule are disabled for a defined length of time after creating a new alert. The rule is still running and creates alert records provided the criteria is met. Allowing you time to correct the problem without running duplicate actions.

### Configure playbook security event by using Azure Sentinel
Microsoft Azure Sentinel is a scalable, cloud-native, security information event management (SIEM) and security orchestration automated response (SOAR) solution. Azure Sentinel delivers intelligent security analytics and threat intelligence across the enterprise, providing a single solution for alert detection, threat visibility, proactive hunting, and threat response.

What can Azure Sentinel do?
* Collect data at cloud scale across all users, devices, applications, and infrastructure, both on-premises and in multiple clouds.
* Detect previously undetected threats, and minimize false positives using Microsoft's analytics and unparalleled threat intelligence.
* Investigate threats with artificial intelligence, and hunt for suspicious activities at scale, tapping into years of cyber security work at Microsoft.
* Respond to incidents rapidly with built-in orchestration and automation of common tasks.

Sentinel uses data connectors within the Azure and 365 fabric to pull data, conduct analysis, and use playbooks to automate remediation

- _connectors_ = template to injest elements from on solution to sentinel (come with workbooks, queries, etc)
- _playbook_ = logic app; you can use logic app designer

### Investigate escalated security incidents
Home > Azure Sentinel workspaces > Azure Sentinel | Incidents > Incident
- use the investigate button

The investigation graph provides you with:

* Visual context from raw data - The live, visual graph displays entity relationships extracted automatically from the raw data. This enables you to easily see connections across different data sources.

* Full investigation scope discovery - Expand your investigation scope using built-in exploration queries to surface the full scope of a breach.

* Built-in investigation steps - Use predefined exploration options to make sure you are asking the right questions in the face of a threat.

NOTE: You will only be able to investigate the incident if you used the entity mapping fields when you set up your analytic rule. The investigation graph requires that your original incident includes entities.

### Configure data classification
What is Azure Information Protection (AIP)? a cloud-based solution that helps an organization to classify and optionally, protect its documents and emails by applying labels. Labels can be applied automatically by administrators who define rules and conditions, manually by users, or a combination where users are given recommendations.

### Configure data retention
1. Retention wins over deletion
2. The longest retention period wins
3. Explicit inclusion wins over implicit inclusion.
4. The shortest deletion period wins

**Maximum numbers for the retention policy:**
* 1,000 mailboxes
* 1,000 Microsoft 365 groups
* 1,000 users for Teams private chats
* 100 sites (OneDrive or SharePoint)

### Configure data sovereignty
where our data is located, regulatory concerns, 
## Configure security for data infrastructure[secure data and applications]
### Enable database authentication
Azure Active Directory authentication is a mechanism of connecting to Azure SQL Database, Managed Instance, and Azure Synapse Analytics by using identities in Azure Active Directory (Azure AD).

Connection strings - 

Managed instanced need at least read permission before for the role before it's created

### Enable database auditing
Auditing for Azure SQL Database and Azure Synapse Analytics tracks database events and writes them to an audit log in your Azure storage account, Log Analytics workspace, or Event Hubs.

How do I define server-level vs. database-level auditing policy? -

An auditing policy can be defined for a specific database or as a default server policy in Azure (which hosts SQL Database or Azure Synapse):

• A server policy applies to all existing and newly created databases on the
server.

• If server auditing is enabled, it always applies to the database. The
database will be audited, regardless of the database auditing settings.

• Enabling auditing on the database, in addition to enabling it on the server,
does not override or change any of the settings of the server auditing. Both audits will exist side by side. In other words, the database is audited twice in parallel; once by the server policy and once by the database policy.

The default auditing policy includes all actions and the following set of action groups, which will audit all the queries and stored procedures executed against the database, as well as successful and failed logins:

• BATCH_COMPLETED_GROUP
• SUCCESSFUL_DATABASE_AUTHENTICATION_GROUP
• FAILED_DATABASE_AUTHENTICATION_GROUP
NOTE: Azure SQL Database and Azure Synapse Audit stores 4000 characters of data for character fields in an audit record. When the statement or the data_sensitivity_information values returned from an auditable action contain more than 4000 characters, any data beyond the first 4000 characters will be truncated and not audited.

### Configure Azure SQL Database Advanced Threat Protection
Configure Azure SQL Database Advanced Threat Protection

Advanced Threat Protection for Azure SQL Database, Azure SQL Managed Instance and Azure Synapse detects anomalous activities indicating unusual and potentially harmful attempts to access or exploit databases.

Advanced Threat Protection is part of the Advanced data security offering, which is a unified package for advanced SQL security capabilities. Advanced Threat Protection can be accessed and managed via the central SQL ADS portal.

Advanced Threat Protection can identify Potential SQL injection, Access from unusual location or data center, Access from unfamiliar principal or potentially harmful application, and Brute force SQL credentials.
### Configure access control for storage accounts / Configure Azure AD authentication for Azure Storage
Azure Storage supports using Azure Active Directory (Azure AD) to authorize requests to Blob and Queue storage. With Azure AD, you can use role-based access control (RBAC) to grant permissions to a security principal, which may be a user, group, or application service principal.

The security principal is authenticated by Azure AD to return an OAuth 2.0 token. The token can then be used to authorize a request against Blob or Queue storage.

NOTE: Microsoft recommends using Azure AD authorization with your blob and queue applications when possible to minimize potential security vulnerabilities inherent in Shared Key.

Authorization with Azure AD is available for all general-purpose and Blob storage accounts in all public regions and national clouds. Only storage accounts created with the Azure Resource Manager deployment model support Azure AD authorization.

NOTE: Authorization with Azure AD is not supported for Azure Table storage. Use Shared Key to authorize requests to Table storage.

When a security principal (a user, group, or application) attempts to access a blob or queue resource, the request must be authorized, unless it is a blob available for anonymous access.

With Azure AD, access to a resource is a two-step process:

First, the security principal's identity is authenticated and an OAuth 2.0
token is returned.

Second, the token is passed as part of a request to the Blob or Queue service
and used by the service to authorize access to the specified resource.

The authentication step requires that an application request an OAuth 2.0 access token at runtime. If an application is running from within an Azure entity such as an Azure VM, a virtual machine scale set, or an Azure Functions app, it can use a managed identity to access blobs or queues.

The authorization step requires that one or more RBAC roles be assigned to the security principal. Azure Storage provides RBAC roles that encompass common sets of permissions for blob and queue data. The roles that are assigned to a security principal determine the permissions that the principal will have.

NOTE: Native applications and web applications that make requests to the Azure Blob or Queue service can also authorize access with Azure AD.

How do I assign RBAC roles for access rights? -

Azure Active Directory (Azure AD) authorizes access rights to secured resources through role-based access control (RBAC). Azure Storage defines a set of built-in RBAC roles that encompass common sets of permissions used to access blob and queue data. You can also define custom roles for access to blob and queue data.

When an RBAC role is assigned to an Azure AD security principal, Azure grants access to those resources for that security principal. Access can be scoped to the level of the subscription, the resource group, the storage account, or an individual container or queue. An Azure AD security principal may be a user, a group, an application service principal, or a managed identity for Azure resources.

What are the Built-in RBAC roles for blobs and queues? -

Azure provides the following built-in RBAC roles for authorizing access to blob and queue data using Azure AD and OAuth:

• Storage Blob Data Owner: Use to set ownership and manage POSIX access
control for Azure Data Lake Storage Gen2.

• Storage Blob Data Contributor: Use to grant read/write/delete permissions to
Blob storage resources.

• Storage Blob Data Reader: Use to grant read-only permissions to Blob storage
resources.

• Storage Queue Data Contributor: Use to grant read/write/delete permissions
to Azure queues.

• Storage Queue Data Reader: Use to grant read-only permissions to Azure queues.

• Storage Queue Data Message Processor: Use to grant peek, retrieve, and
delete permissions to messages in Azure Storage queues.

• Storage Queue Data Message Sender: Use to grant add permissions to messages
in Azure Storage queues.

NOTE: RBAC role assignments may take up to five minutes to propagate.

Only roles explicitly defined for data access permit a security principal to access blob or queue data. Roles such as Owner, Contributor, and Storage Account Contributor permit a security principal to manage a storage account, but do not provide access to the blob or queue data within that account.

What is the concept of "Resource scope"? -

Before you assign an RBAC role to a security principal, determine the scope of access that the security principal should have. Best practices dictate that it's always best to grant only the narrowest possible scope.

The following list describes the levels at which you can scope access to Azure blob and queue resources, starting with the narrowest scope:

• An individual container - At this scope, a role assignment applies to all of
the blobs in the container, as well as container properties and metadata.

• An individual queue - At this scope, a role assignment applies to messages
in the queue, as well as queue properties and metadata.

• The storage account - At this scope, a role assignment applies to all
containers and their blobs, or to all queues and their messages.

• The resource group - At this scope, a role assignment applies to all of the
containers or queues in all of the storage accounts in the resource group.

• The subscription - At this scope, a role assignment applies to all of the
containers or queues in all of the storage accounts in all of the resource groups in the subscription.

NOTE: If your subscription includes an Azure DataBricks namespace, roles that are scoped to the subscription will not grant access to blob and queue data. Scope roles to the resource group, storage account, or container or queue instead.

### Configure key management for storage accounts
When you create a storage account, Azure generates two 512-bit storage account access keys. These keys can be used to authorize access to data in your storage account via Shared Key authorization.

Microsoft recommends that you use Azure Key Vault to manage your access keys, and that you regularly rotate and regenerate your keys. (You can also manually rotate your keys)

NOTE: Avoid distributing access keys to other users, hard-coding them, or saving them anywhere in plain text that is accessible to others. Rotate your keys if you believe they may have been compromised.

How do I use Azure Key Vault to manage access keys? -

An Azure storage account uses credentials comprising an account name and a key. The key is autogenerated and serves as a password, rather than an as a cryptographic key.

Key Vault manages storage account keys by periodically regenerating them in storage account and provides shared access signature tokens for delegated access to resources in your storage account.

You can use the Key Vault managed storage account key feature to list (sync) keys with an Azure storage account, and regenerate (rotate) the keys periodically.

NOTE: You can manage keys for both storage accounts and Classic storage accounts.

When you use the managed storage account key feature, consider the following points:

• Key values are never returned in response to a caller.

• Only Key Vault should manage your storage account keys. (Do not manage the
keys yourself and avoid interfering with Key Vault processes.)

• Only a single Key Vault object should manage storage account keys.
• Do not allow key management from multiple objects.

• You can request Key Vault to manage your storage account with a user
principal, but not with a service principal.

Microsoft recommends using Azure Storage integration with Azure Active Directory (Azure AD), Microsoft's cloud-based identity and access management service.

Azure AD integration is available for Azure blobs and queues, and provides OAuth2 token-based access to Azure Storage (just like Azure Key Vault).

Azure AD allows you to authenticate your client application by using an application or user identity, instead of storage account credentials.

You can use an Azure AD managed identity when you run on Azure. Managed identities remove the need for client authentication and storing credentials in or with your application.

Azure AD uses role-based access control (RBAC) to manage authorization, which is also supported by Key Vault.

How do I manually rotate access keys? -
Two access keys are assigned so that you can rotate your keys. Having two keys ensures that your application maintains access to Azure Storage throughout the process.
##### NOTE: Regenerating your access keys can affect any applications or Azure services that are dependent on the storage account key. Any clients that use the account key to access the storage account must be updated to use the new key, including media services, cloud, desktop and mobile applications, and graphical user interface applications for Azure Storage, such as Azure Storage Explorer.
**To rotate your storage account access keys in the Azure portal:**
1. Update the connection strings in your application code to reference the secondary access key for the storage account.
2. Navigate to your storage account in the Azure portal.
3. Under Settings, select Access keys.
4. To regenerate the primary access key for your storage account, select the Regenerate button next to the primary access key.
5. Update the connection strings in your code to reference the new primary access key.
6. Regenerate the secondary access key in the same manner.
##### *NOTE:* Microsoft recommends using only one of the keys in all of your applications at the same time. If you use Key 1 in some places and Key 2 in others, you will not be able to rotate your keys without some application losing access.
To rotate an account's access keys, the user must either be a Service Administrator, or must be assigned an RBAC role that includes the Microsoft.Storage/storageAccounts/regeneratekey/action.
Some built-in RBAC roles that include this action are the Owner, Contributor, and Storage Account Key Operator Service Role roles.
**To rotate your storage account access keys with PowerShell -**
1. Update the connection strings in your application code to reference the secondary access key for the storage account.
2. Call the New-AzStorageAccountKey command to regenerate the primary access key, as shown in the following example:
New-AzStorageAccountKey -ResourceGroupName <resource-group> -Name <storage-account> -KeyName key1
3. Update the connection strings in your code to reference the new primary access key.
4. Regenerate the secondary access key in the same manner. To regenerate the secondary key, use key2 as the key name instead of key1.

### Configure Azure AD Domain Services authentication for Azure Files
Configure Azure AD Domain Services authentication for Azure Files

Azure Files supports identity-based authentication over Server Message Block (SMB) through on-premises Active Directory Domain Services (AD DS) and Azure Active Directory Domain Services (Azure AD DS).

Enabling identity-based access for your Azure file shares allows you to replace existing file servers with Azure file shares without replacing your existing directory service, maintaining seamless user access to shares.

Azure Files enforces authorization on user access to both the share and the directory/file levels. Share-level permission assignment can be performed on Azure Active Directory (Azure AD) users or groups managed through the role-based access control (RBAC) model.

With RBAC, the credentials you use for file access should be available or synced to Azure AD. You can assign built-in RBAC roles like Storage File Data SMB Share Reader to users or groups in Azure AD to grant read access to an Azure file share.

At the directory/file level, Azure Files supports preserving, inheriting, and enforcing Windows DACLs just like any Windows file servers.

You can choose to keep Windows DACLs when copying data over SMB between your existing file share and your Azure file shares. Whether you plan to enforce authorization or not, you can use Azure file shares to back up ACLs along with your data.

Vocabulary you should know for the exam -

• Kerberos authentication - used to verify the identity of a user or host.

• Server Message Block (SMB) protocol - industry-standard network
file-sharing protocol; also known as Common Internet File System or CIFS.

• Azure Active Directory (Azure AD) - Microsoft's multi-tenant cloud-based
directory and identity management service. Azure AD combines core directory services, application access management, and identity protection into a single solution. Azure AD-joined Windows virtual machines (VMs) can access Azure file shares with your Azure AD credentials.

• Azure Active Directory Domain Services (Azure AD DS) - provides managed
domain services such as domain join, group policies, LDAP, and Kerberos/NTLM authentication. These services are fully compatible with Active Directory Domain Services.

• On-premises Active Directory Domain Services (AD DS) - integration with
Azure Files provides the methods for storing directory data while making it available to network users and administrators. Security is integrated with AD DS through logon authentication and access control to objects in the directory.

• Azure Role Based Access Control (RBAC) - enables fine-grained access
management for Azure. Using RBAC, you can manage access to resources by granting users the fewest permissions needed to perform their jobs.

What are the common use cases for doing this? -

Identity-based authentication and support for Windows ACLs on Azure Files is best leveraged for the following use cases:

Replace on-premises file servers -

Azure file shares with on-premises AD DS authentication is the best fit here, when you can migrate the data to Azure Files. A complete migration will allow you to take advantage of the high availability and scalability benefits while also minimizing the client-side changes.

Lift and shift applications to Azure -

Azure file shares provide the option to integrate with either Azure AD DS or on-premises AD DS for authentication.

Backup and disaster recovery (DR) -

If you are keeping your primary file storage on-premises, Azure file shares can serve as an ideal storage for backup or DR, to improve business continuity. You can use Azure file shares to back up your data from existing file servers, while preserving Windows DACLs. For DR scenarios, you can configure an authentication option to support proper access control enforcement at failover.

What do I need to know before doing this? -

Azure AD DS authentication - Azure AD DS-joined Windows machines can access Azure file shares with Azure AD credentials over SMB.

On-premises AD DS authentication - On-premises AD DS-joined or Azure AD DS-joined Windows machines can access Azure file shares with on-premises Active Directory credentials that are synched to Azure AD over SMB.

Restrictions -

• Azure AD DS and on-premises AD DS authentication do not support
authentication against computer accounts. You can consider using a service logon account instead.

• Neither Azure AD DS authentication nor on-premises AD DS authentication is
supported against Azure AD-joined devices or Azure AD-registered devices.

• Azure file shares only support identity-based authentication against one of
the following domain services, either Azure Active Directory Domain Services (Azure AD DS) or on-premises Active Directory Domain Services (AD DS).

How does it actually work? -

Azure file shares leverages the Kerberos protocol for authenticating with either on-premises AD DS or Azure AD DS.

When an identity associated with a user or application running on a client attempts to access data in Azure file shares, the request is sent to the domain service, either AD DS or Azure AD DS, to authenticate the identity.

If authentication is successful, it returns a Kerberos token. The client sends a request that includes the Kerberos token and Azure file shares use that token to authorize the request.

Azure file shares only receive the Kerberos token, not access credentials.

What do I have to do to setup and use AD DS? -

For on-premises AD DS authentication, you must set up your AD domain controllers and domain join your machines or VMs. You can host your domain controllers on Azure VMs or on-premises.

Either way, your domain joined clients must have line of sight to the domain service, so they must be within the corporate network or virtual network (VNET) of your domain service.

The on-prem AD DS must be synced to Azure AD using Azure AD Connect sync.

NOTE: Only hybrid users that exist in both on-premises AD DS and Azure AD can be authenticated and authorized for Azure file share access. This is because the share level permission is configured against the identity represented in Azure AD where the directory/file level permission is enforced with that in AD DS.

Make sure that you configure the permissions correctly against the same hybrid user.

What do I have to do to setup and use Azure AD DS? -

For Azure AD DS authentication, you should enable Azure AD Domain Services and domain join the VMs you plan to access file data from. Your domain-joined VM must reside in the same virtual network (VNET) as your Azure AD DS.

There are two major differences:

First, you do not need to create the identity in Azure AD DS to represent the storage account. This is performed by the enablement process in the background.

Second, all users exist in Azure AD can be authenticated and authorized. The user can be cloud only or hybrid. The sync from Azure AD to Azure AD DS is managed by the platform without requiring any user configuration.

However, the client must be domain joined to Azure AD DS, it cannot be Azure AD joined or registered.

How do I enable Azure AD DS authentication for a storage account? -

To enable Azure AD DS authentication over SMB for Azure Files, you can set a property on storage accounts by using the Azure portal, Azure PowerShell, or Azure CLI.

Setting this property implicitly "domain joins" the storage account with the associated Azure AD DS deployment. Azure AD DS authentication over SMB is then enabled for all new and existing file shares in the storage account.

NOTE: You can enable Azure AD DS authentication over SMB only after you have successfully deployed Azure AD DS to your Azure AD tenant.

##### Azure portal:

1. In the Azure portal, go to your existing storage account, or create a storage account.

2. In the Settings section, select Configuration.

3. Under Identity-based access for file shares switch the toggle for Azure Active Directory Domain Service (AAD DS) to Enabled.

4. Select Save.

PowerShell:

To enable Azure AD DS authentication over SMB with Azure PowerShell, install the latest Az module (2.4 or newer) or the Az.Storage module (1.5 or newer).

To create a new storage account, call New-AzStorageAccount, and then set the EnableAzureActiveDirectoryDomainServicesForFile parameter to true.

In the following example, remember to replace the placeholder values with your own values. (If you were using the previous preview module, the parameter for feature enablement is EnableAzureFilesAadIntegrationForSMB.)

Create a new storage account
New-AzStorageAccount -ResourceGroupName "<resource-group-name>" -Name "<storage-account-name>" -Location "<azure-region>" -SkuName Standard_LRS -Kind StorageV2 ` -EnableAzureActiveDirectoryDomainServicesForFile $true

Update a storage account
Set-AzStorageAccount -ResourceGroupName "<resource-group-name>" -Name "<storage-account-name>" -EnableAzureActiveDirectoryDomainServicesForFile $true

Azure CLI:

To enable Azure AD authentication over SMB with Azure CLI, install the latest CLI version (Version 2.0.70 or newer).

To create a new storage account, call az storage account create, and set the --enable-files-aadds property to true. In the following example, remember to replace the placeholder values with your own values. (If you were using the previous preview module, the parameter for feature enablement is file-aad.)

Create a new storage account
az storage account create -n <storage-account-name> -g <resource-group-name> --enable-files-aadds $true

Update a new storage account
az storage account update -n <storage-account-name> -g <resource-group-name> --enable-files-aadds $true

How do I assign access permissions to an identity? -

To access Azure Files resources with identity based authentication, an identity (a user, group, or service principal) must have the necessary permissions at the share level.

This process is similar to specifying Windows share permissions, where you specify the type of access that a particular user has to a file share.

Microsoft has introduced three Azure built-in roles for granting share-level permissions to users:

• Storage File Data SMB Share Reader - allows read access in Azure Storage
file shares over SMB.

• Storage File Data SMB Share Contributor - allows read, write, and delete
access in Azure Storage file shares over SMB.

• Storage File Data SMB Share Elevated Contributor - allows read, write,
delete and modify NTFS permissions in Azure Storage file shares over SMB.

NOTE: Full administrative control of a file share, including the ability to take ownership of a file, requires using the storage account key. Administrative control is not supported with Azure AD credentials.

You can use the Azure portal, PowerShell, or Azure CLI to assign the built-in roles to the Azure AD identity of a user for granting share-level permissions. Be aware that the share level RBAC role assignment can take some time to be in effect.

NOTE: Remember to sync your AD DS credentials to Azure AD if you plan to use your on-premises AD DS for authentication. Password hash sync from AD DS to Azure AD is optional. Share level permission will be granted to the Azure AD identity that is synced from your on-premises AD DS.

The general recommendation is to use share level permission for high level access management to an AD group representing a group of users and identities, then leverage NTFS permissions for granular access control on directory/file level.

##### Azure portal:

1. In the Azure portal, go to your file share, or Create a file share.

2. Select Access Control (IAM).

3. Select Add a role assignment

4. In the Add role assignment blade, select the appropriate built-in role (Storage File Data SMB Share Reader, Storage File Data SMB Share Contributor) from the Role list. Leave Assign access to at the default setting: Azure AD user, group, or service principal. Select the target Azure AD identity by name or email address.

5. Select Save to complete the role assignment operation.

How do I configure NTFS permissions over SMB? -

After you assign share-level permissions with RBAC, you must assign proper NTFS permissions at the root, directory, or file level. Think of share-level permissions as the high-level gatekeeper that determines whether a user can access the share. Whereas NTFS permissions act at a more granular level to determine what operations the user can do at the directory or file level.

Azure Files supports the full set of NTFS basic and advanced permissions. You can view and configure NTFS permissions on directories and files in an Azure file share by mounting the share and then using Windows File Explorer or running the Windows icacls or Set-ACL command.

To configure NTFS with superuser permissions, you must mount the share by using your storage account key from your domain-joined VM.

The following sets of permissions are supported on the root directory of a file share:

BUILTIN\Administrators:(OI)(CI)(F) NT AUTHORITY\SYSTEM:(OI)(CI)(F) BUILTIN\Users:(RX) BUILTIN\Users:(OI)(CI)(IO)(GR,GE) NT AUTHORITY\Authenticated Users:(OI)(CI)(M) NT AUTHORITY\SYSTEM:(F) CREATOR OWNER:(OI)(CI)(IO)(F)

### Create and manage Shared Access Signatures (SAS)
Create and manage Shared Access Signatures (SAS)

A shared access signature (SAS) provides secure delegated access to resources in your storage account without compromising the security of your data. With a SAS, you have granular control over how a client can access your data. You can control what resources the client may access, what permissions they have on those resources, and how long the SAS is valid, among other parameters.

What are the types of shared access signatures? -

Azure Storage supports three types of shared access signatures:

• User delegation SAS - A user delegation SAS is secured with Azure Active
Directory (Azure AD) credentials and also by the permissions specified for the SAS. A user delegation SAS applies to Blob storage only.

• Service SAS - A service SAS is secured with the storage account key. A
service SAS delegates access to a resource in only one of the Azure Storage services: Blob storage, Queue storage, Table storage, or Azure Files.

• Account SAS - An account SAS is secured with the storage account key. An
account SAS delegates access to resources in one or more of the storage services.

All of the operations available via a service or user delegation SAS are also available via an account SAS.

Additionally, with the account SAS, you can delegate access to operations that apply at the level of the service, such as Get/Set Service Properties and Get Service Stats operations.

You can also delegate access to read, write, and delete operations on blob containers, tables, queues, and file shares that are not permitted with a service SAS.

A shared access signature can take one of two forms:

• Ad hoc SAS - When you create an ad hoc SAS, the start time, expiry time, and
permissions for the SAS are all specified in the SAS URI (or implied, if start time is omitted). Any type of SAS can be an ad hoc SAS.

NOTE: A user delegation SAS or an account SAS must be an ad hoc SAS. Stored access policies are not supported for the user delegation SAS or the account SAS.

• Service SAS with stored access policy - A stored access policy is defined
on a resource container, which can be a blob container, table, queue, or file share. The stored access policy can be used to manage constraints for one or more service shared access signatures. When you associate a service SAS with a stored access policy, the SAS inherits the constraints — the start time, expiry time, and permissions defined for the stored access policy.

How does a shared access signature work? -

A shared access signature is a signed URI that points to one or more storage resources and includes a token that contains a special set of query parameters.

The token indicates how the resources may be accessed by the client. One of the query parameters, the signature, is constructed from the SAS parameters and signed with the key that was used to create the SAS.

This signature is used by Azure Storage to authorize access to the storage resource.

You can sign a SAS in one of two ways:

• With a user delegation key that was created using Azure Active Directory
(Azure AD) credentials - A user delegation SAS is signed with the user delegation key.

To get the user delegation key and create the SAS, an Azure AD security principal must be assigned a role-based access control (RBAC) role that includes the Microsoft.Storage/storageAccounts/blobServices/generateUserDelegationKey action.

• With the storage account key - Both a service SAS and an account SAS are
signed with the storage account key. To create a SAS that is signed with the account key, an application must have access to the account key.

What about the SAS token? -

The SAS token is a string that you generate on the client side, for example by using one of the Azure Storage client libraries.

The SAS token is not tracked by Azure Storage in any way. You can create an unlimited number of SAS tokens on the client side.

After you create a SAS, you can distribute it to client applications that require access to resources in your storage account.

When a client application provides a SAS URI to Azure Storage as part of a request, the service checks the SAS parameters and signature to verify that it is valid for authorizing the request.

If the service verifies that the signature is valid, then the request is authorized.

Otherwise, the request is declined with error code 403 (Forbidden).

When would I have to use a shared access signature? -

Use a SAS when you want to provide secure access to resources in your storage account to any client who does not otherwise have permissions to those resources.

Additionally, a SAS is required to authorize access to the source object in a copy operation in certain scenarios:

• When you copy a blob to another blob that resides in a different storage
account, you must use a SAS to authorize access to the source blob. You can optionally use a SAS to authorize access to the destination blob as well.

• When you copy a file to another file that resides in a different storage
account, you must use a SAS to authorize access to the source file. You can optionally use a SAS to authorize access to the destination file as well.

• When you copy a blob to a file, or a file to a blob, you must use a SAS to
authorize access to the source object, even if the source and destination objects reside within the same storage account.

What are the best practices that I should deploy when using SAS? -

When you use shared access signatures in your applications, you need to be aware of two potential risks:

• If a SAS is leaked, it can be used by anyone who obtains it, which can
potentially compromise your storage account.

• If a SAS provided to a client application expires and the application is
unable to retrieve a new SAS from your service, then the application's functionality may be hindered.

The following recommendations for using shared access signatures can help mitigate these risks:

• Always use HTTPS to create or distribute a SAS - If a SAS is passed over
HTTP and intercepted, an attacker performing a man-in-the-middle attack is able to read the SAS and then use it just as the intended user could have.

• Use a user delegation SAS when possible - A user delegation SAS provides
superior security to a service SAS or an account SAS. A user delegation SAS is secured with Azure AD credentials, so that you do not need to store your account key with your code.

• Have a revocation plan in place for a SAS - Make sure you are prepared to
respond if a SAS is compromised.

• Define a stored access policy for a service SAS - Stored access policies give
you the option to revoke permissions for a service SAS without having to regenerate the storage account keys. Set the expiration on these very far in the future (or infinite) and make sure it is regularly updated to move it farther into the future.

• Use near-term expiration times on an ad hoc SAS service SAS or account SAS -
In this way, even if a SAS is compromised, it is valid only for a short time. This practice is especially important if you cannot reference a stored access policy.

• Be careful with SAS start time - If you set the start time for a SAS to now,
then due to clock skew (differences in current time according to different machines), failures may be observed intermittently for the first few minutes.

In general, set the start time to be at least 15 minutes in the past. Or, do not set it at all, which will make it valid immediately in all cases. The same generally applies to expiry time as well--remember that you may observe up to 15 minutes of clock skew in either direction on any request.

• Be careful with SAS datetime format - If you set the start time and/or
expiry for a SAS, for some utilities (for example for the command-line utility AzCopy) you need the datetime format to be '+%Y-%m-%dT%H:%M:%SZ', specifically including the seconds in order for it to work using the SAS token.

• Be specific with the resource to be accessed - A security best practice is
to provide a user with the minimum required privileges.

• Validate data written using a SAS - If your application requires that data
be validated or authorized before it is ready to use, you should perform this validation after the data is written and before it is used by your application. This practice also protects against corrupt or malicious data being written to your account, either by a user who properly acquired the SAS, or by a user exploiting a leaked SAS.

• Know when not to use a SAS - For example, if you want to make all blobs in
a container publicly readable, you can make the container Public, rather than providing a SAS to every client for access.

• Use Azure Monitor and Azure Storage logs to monitor your application - You
can use Azure Monitor and storage analytics logging to observe any spike in authorization failures due to an outage in your SAS provider service or to the inadvertent removal of a stored access policy.

